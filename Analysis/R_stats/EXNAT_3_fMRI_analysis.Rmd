---
title: "EXNAT_3_fMRI_analysis"
author: "Sandra Martin"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r file setup, echo = FALSE}
rm(list = ls()) # clear environment
knitr::opts_chunk$set() # set default options for all code blocks in this document
options(scipen = 999) # don't use scientific notation for very large or small numbers
```

# Load packages
```{r packages, echo = FALSE, message = FALSE, warning = TRUE}
# Create a list with needed libraries
pkgs <- c("here", # for working with relative paths
          "ggeffects", # create data frames of marginal effects for 'ggplot' from model outputs
          "stringr", # for getting substrings
          "ggplot2", # for plots
          "dplyr", # for replacing multiple values in vector with different values
          "reshape2", # for reshaping df format
          "tidyverse", # for aggregating
          "psycho", # for computing d-prime values
          "devtools", # for getting packages from github
          "gtools", # for getting tuples from list
          "see", # for plotting residuals of lme4 model
          "performance", # needed for plotting the lme4 model output summary
          "lme4", # also for linear mixed models, but no p-values in the summary
          "lmerTest", # extension of lme4 - for tab_model() for showing lme4 model results
          "modelsummary", # for printing model fit measures
          "car", # for basic Anova() function & aGSIFs (= basically weird adjusted VIFs)
          "sjPlot", # for running Anova & showing results in a HTML table in the Viewer
          "colorspace", # for beautiful and balanced color palettes
          "readxl", # reading in Excel tables
          "interactions") # for simple slopes analysis


# Load each listed library, check if it's already installed
# and install if necessary
for (pkg in pkgs){
  if(!require(pkg, character.only = TRUE)){
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}

# install package with lists of stop words from github
devtools::install_github("quanteda/stopwords")
library(stopwords)
```

# Load d-prime function from different R script:
```{r source d-prime function, echo = FALSE}
source(here::here("get_dprime.R")) # get script
```

# Load R Data
```{r}
load(here::here("RData/exp_all_data.RData")) # df with all trials and participants incl demographic information
load(here::here("RData/exp_df_comprehension_questions.RData")) # df with comprehension question accuracy
```


# Settings for plots
```{r Theme for plots, echo = FALSE}
apatheme <- theme_bw()+
  theme(plot.title = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        text = element_text(family = 'sans',size = 14)) #panel.grid.major=element_blank(),

today <- Sys.Date()
today <- format(today, format="%y%m%d")


# Custom colour palettes for the plots:

# for distinguishing between paced and unpaced task:
palet_task_condition <- c("#D2BFE7",
                      "#977FB2") 
palet_task_condition_lines <- c("#ad8bd3",
                      "#7B5EC6") 

# for distinguishing between cognitive load conditions: 
# palet_load <- c("#575A7B", # Reading Only
#                 "#ED9201", # 1-back
#                 "#982126") # 2-back
palet_load <- c("#4B201D", "#9F4D48", "#F8A29E")

# for distinguishing between n-back tasks (single- & dual 1- and 2-back)
palet_dprimes = c("#ED9201", # 1-back Dual
                  "#fec160", # 1-back Single
                  "#982126", # 2-back Dual
                  "#d95459") # 2-back Single
palet_dprimes_lines = c("#cb7d00", # 1-back Dual
                        "#ED9201", # 1-back Single
                        "#982126", # 2-back Dual
                        "#d95459") # 2-back Single

# for simple slopes plots:
palet_simple_slopes = c("#585858", # n.s.
                        "#0c6ae8") # sign.

# For effects we don't really have colours for. Like age or surprisal.
palet_effects <- c("#365464") 

```


# Set path to datasets
```{r path setup, echo = FALSE}
path_data_folder <- here::here("Raw_data/fMRI_experiment/")
```

# Read in data & do preprocessing on participant-level
In this chunk, we read in every dataset individually, compute reading times, reading speed, d-primes, comprehension question performance, and so on, 
add a few information on the words we used (e.g. surprisal scores on our 4 time scales, word frequencies, word lengths, punctuation,...), 
and then we exclude data on block level:
We only exclude data on block-level if performance measures indicate they didn't do the task(s) correctly.
```{r Read in data, message=FALSE, echo=FALSE}
# Get list of all .csv files in the data folder
file_list <- list.files(path = path_data_folder, pattern='.csv')

# Placeholders df for demographics, questions & text data
df_all_data        <- data.frame()
df_comprehension_Qs <- data.frame()

# Loop files in my file list aka directory
for (i in 1:length(file_list)) {

  # PREPARE FILE FOR PREPROCESSING
  # Read in current file
  subj_df <- read.csv(paste(path_data_folder, file_list[i],sep = ""), sep = ",")

  # If the df is separated by a semicolon instead of a comma, we only get
  # one messed-up column. In this case, use semicolon as separator for csv:
  if (ncol(subj_df) == 1) {
   subj_df <- read.csv(paste(path_data_folder, file_list[i],sep = ""), sep = ";")
  }
  
  id <- subj_df$participant[1]
  
  # print message
  message(paste(i, " - Reading in file ", file_list[i], ", participant ID: ", id, sep = ""))

  # add column with info on whether participant should be excluded
  excl <- FALSE
  
  # rename block_kind column
  subj_df <- subj_df %>% 
    rename(nback_level = n.back_level)

  # GET RAW TEXT & N-BACK DATA

  # get words & information on the text from data
  subj_df <- subj_df[, c("colour", "target", "nback_response", "nback_RT", "duration", "text_nr", "trial_nr", "block_nr_exp", "run_nr", "block_nr_run", "block_name", "nback_level", "word", "question", "button_pressed", "chosen_ans", "ans_correct", "RT_per_rectangle_oneback_single", "RT_per_rectangle_twoback_single", "RT_per_letter_baseline", "RT_per_letter_oneback_dual", "RT_per_letter_twoback_dual", "participant", "session", "date")]
  
  # remove weird empty rows
  subj_df <- subset(subj_df, !is.na(run_nr))

  
  ### ADD NUMBERED BLOCK NAMES ####

  # # We have each main block twice, but I would like to exclude outliers by block and not by condition.
  # # Reason: Reading times in second block might be slightly different than in first block, so don't mix them up.
  # 
  change_df <- subj_df %>%
    filter(!is.na(trial_nr)) %>%
    group_by(run_nr, block_nr_run, block_name) %>%
    count() %>%
    ungroup() %>%
    group_by(block_name) %>%
    mutate(Index=1:n()) %>%
    mutate(block_names_numbered = paste(block_name, Index, sep = "_")) %>%
    select(-c(Index, n))

  subj_df <- full_join(subj_df, change_df)

  ### MERGE INFO ON RT PER LETTER INTO ONE COLUMN ####
  subset_df <- subj_df %>% 
    select(c(block_name, starts_with("RT_per_"))) %>% 
    mutate(Paced_RT = case_when(
      block_name == "Reading_Baseline_main_no_click" ~ RT_per_letter_baseline[!is.na(subj_df$RT_per_letter_baseline)][1],
      block_name == "Reading_pseudotext_no_click" ~ RT_per_letter_baseline[!is.na(subj_df$RT_per_letter_baseline)][1],
      block_name == "1back_dual_main_no_click" ~ RT_per_letter_oneback_dual[!is.na(subj_df$RT_per_letter_oneback_dual)][1],
      block_name == "2back_dual_main_no_click" ~ RT_per_letter_twoback_dual[!is.na(subj_df$RT_per_letter_twoback_dual)][1],
      block_name == "1back_single_main_no_click" ~ RT_per_rectangle_oneback_single[!is.na(subj_df$RT_per_rectangle_oneback_single)][1],
      block_name == "2back_single_main_no_click" ~ RT_per_letter_twoback_dual[!is.na(subj_df$RT_per_letter_twoback_dual)][1],
    )) %>% 
    select(c(block_name, Paced_RT)) %>% 
    distinct()
  
  subj_df <- full_join(subj_df, subset_df)

  
  # GET ADDITIONAL INFORMATION ON THE TEXTS:

  ### PUNCTUATION ####

  # Edit the texts a bit. Currently, we have words & punctuation
  # mixed up. Would be nice if we had one word column
  # and some others with info on punctuation.

  punctuation <- c(rep("", times = length(subj_df$participant)))

  # get all .
  punctuation[grep("[.]", subj_df$word)] <- "point"
  # get all ?
  punctuation[grep("[?]", subj_df$word)] <- "question_mark"
  # get all !
  punctuation[grep("[!]", subj_df$word)] <- "exclamation_mark"
  # get all ,
  punctuation[grep("[,]", subj_df$word)] <- "comma"
  # get all ;
  punctuation[grep("[;]", subj_df$word)] <- "semicolon"
  # get all :
  punctuation[grep("[:]", subj_df$word)] <- "colon"

  # get all "
  # This is tricky for various reasons:

  # 1. there could be quotes directly after or
  # before a point for example

  # Idea: Separate column for quotes
  quotes <- c(rep("", times = length(subj_df$participant)))

  # 2. I want to differentiate between opening and closing quotes,
  # but they look the same.

  # Idea: make them all "opening quotes" and change every second one to
  # "closing_quote". This should do the trick.
  quotes[grep("\"", subj_df$word)] <- "opening_quote"
  opening <- TRUE

  # loop list of quotes
  for (x in 1:length(quotes)){
    # get current value in vector "quotes" & current word
    curr_val  <- quotes[x]
    curr_word <- subj_df$word[x]

    if (curr_val == "opening_quote" & # if the current value is not empty
        opening == TRUE & # and we set "opening" to TRUE
        grepl("\"[A-Za-z0-9]+\"", curr_word) == FALSE){ # and there are not 2 quotes around the word

      # leave it as is, next quote is the closing one
      opening <- FALSE

      # if we have a quote, but it has to be a closing one, change it accordingly
    } else if (curr_val == "opening_quote" &
               opening == FALSE &
               grepl("\"[A-Za-z0-9]+\"", curr_word) == FALSE){
      # change value to closing quote
      quotes[x] <- "closing_quote"
      # next quote is the opening one
      opening <- TRUE
      # if it's a quote around a single word, mark as "both"
    } else if (curr_val == "opening_quote" &
               grepl("\"[A-Za-z0-9]+\"", curr_word) == TRUE){
      # change value to both
      quotes[x] <- "both"
    }
  }

  # remove all punctuation
  word_single <- gsub('[[:punct:] ]+',' ', subj_df$word)
  # "trim" away spaces before and after words
  word_single <- trimws(word_single, which = c("left"))
  word_single <- trimws(word_single, which = c("right"))
  # put dashes into spaces between words (words like "ice-cream" for example)
  word_single <- gsub(" ", "-", word_single, fixed = TRUE)

  # get word length for single words
  word_length_single <- nchar(word_single)


  ### N-BACK RESPONSES ####

  # check if we had an n-back reaction while the word was shown
  # create vector with only FALSEs
  reaction <- c(rep(FALSE, times = length(subj_df$participant)))
  # check where in subj_df we have responses (hit or false alarm) and change value in reaction vector to TRUE at that index
  reaction[which(subj_df$nback_response == "hit" | subj_df$nback_response == "false alarm")] <- TRUE

  # APPEND NEW COLUMNS
  # append punctuation and quotes column, column with words without punctuation
  # column with length of each the single words and reaction column as
  # additional columns to subj_df:
  subj_df <- data.frame(cbind(subj_df, word_single, punctuation,
                              quotes, word_length_single, reaction))

  ### STOP WORDS ####

  # Now also get previous reaction and stop words.
  # First, append empty columns to df:
  subj_df[, c("previous_reaction", "previous_duration", "stop_word")] <- ""

  # get list of German stop_words
  stop_words <- stopwords("de", source = "snowball")
  # snowball = stopwords list based on the Snowball stemmer's word lists.
  # --> https://snowballstem.org/texts/introduction.html

  # now loop rows and gradually fill in the empty columns.
  for (idx in 1:length(subj_df$participant)){
    # if it's the first trial of a new block, go to next iteration
    # because in this case we don't have previous data.
    # Also skip the following part if it's a block without text.
    if (subj_df$trial_nr[idx] > 1 && !is.na(subj_df$trial_nr[idx])){
      # fill in the missing data by getting the values from the previous trial:
      subj_df$previous_duration[idx]    <- subj_df$duration[idx-1]
      subj_df$previous_reaction[idx]    <- subj_df$reaction[idx-1]
    }

    if (subj_df$word_single[idx] %in% stop_words){
      # check if current word is a stop word or not
      subj_df$stop_word[idx] <- TRUE 
      }
    else {
      subj_df$stop_word[idx] <- FALSE
    }
  }
  
  ### WORD FREQUENCIES & SURPRISAL SCORES ####

  # Include word frequencies & surprisal scores for each word

  # append "empty" word frequency & surprisal score columns to df
  # to do so, create a vector of column names
  col_names <- c("word_frequency", "surprisal_2", "entropy_2")
  # then add "empty" columns to data frame subj_df
  subj_df[, col_names] <- 0

  # get word frequency & surprisal scores for each word
  # load word freq df
  word_freqs_df = read.csv(here::here("word_frequencies/Word_freqs.csv"), sep = ";", header = TRUE)[2:4]
  # Explanation: We compute the word frequencies using another
  #              script which is called "calculate_word_frequencies.py".
  #              You can find it in the Analysis folder.
  #              --> word frequencies were taken from this python package:
  #              Speer, R., Chin, J., Lin, A., Jewett, S., & Nathan, L. (2018, October 3).
  #              LuminosoInsight/wordfreq: v2.2. Zenodo. https://doi.org/10.5281/zenodo.1443582


  # Load surprisal scores
  surprisal_df = read.csv(here::here("surprisal_scores/vanilla_2words_surprisal_entropy.csv"), sep = ",", header = TRUE)

  # Explanation: I computed the scores in Python using a German GPT-2 model. For each text you can select a context chunk of x words (e.g. 5 words)
  #              and predict the next word. For each possible continuation of your context, you get probabilities.
  #              If you get the probability for the actual word and compute the negative log of it, you have the surprisal score
  #              for your word on time scale x (e.g. 5 words = TS 5). The time scales are all highly correlated, which might be due to the fact that each
  #              time scale also includes context information from all lower timescales, so it's like a Russian doll situation.
  #              To deal with this problem, we masked all words that were already processed in lower time scales,
  #              so each time scale only uses the "new" parts of the input chunk.


  # loop individual texts
  for (curr_text_nr in unique(subj_df$text_nr)){

    # in some blocks we don't have texts, so skip those
    # CAVE: currently also skipping text 10 because I still need to calculate values for this text
    if (curr_text_nr == "" | curr_text_nr == "text_10" | startsWith(curr_text_nr, "pseudo")){
      next
      # if it's a text block, though, assign word frequencies from csv
    } else {
      #print(curr_text_nr) # uncomment this if you'd like to show the texts each participant read

      # get word frequencies for current text nr
      curr_word_freqs <- subset(word_freqs_df, text_nr == curr_text_nr)$word_frequency
      # find out where in the subj_df text the text is located and add the word frequencies there
      subj_df[which(subj_df$text_nr == curr_text_nr & subj_df$question == ""),]$word_frequency <- curr_word_freqs

      # Do the same for the surprisal scores.
      curr_surprisals <- subset(surprisal_df, text_nr == curr_text_nr)

      # find out where in the subj_df text the current text nr is located
      curr_row <- which(subj_df$text_nr == curr_text_nr & subj_df$question == "")

      # add the surprisal scores (untransformed & orthogonalized scores) there
      subj_df[curr_row, c("surprisal_2", "entropy_2")]  <- curr_surprisals[c("surprisal_2_words_context", "entropy_2_words_context")]
      
    }# END if
  }# END loop texts

  
  ### GET SURPRISAL SCORES OF PREVIOUS WORD ####
  # --> basically do the same again as before, but add surprisal scores for current for to row of next word.

  # append "empty" word frequency & surprisal score columns to df
  # to do so, create a vector of column names
  col_names <- c("word_frequency_previous_word", "previous_surprisal_2", "previous_entropy_2")
  # then add "empty" columns to data frame subj_df
  subj_df[, col_names] <- 0

  # loop individual texts
  for (curr_text_nr in unique(subj_df$text_nr)){

    # in some blocks we don't have texts, so skip those
    if (curr_text_nr == "" | curr_text_nr == "text_10" | startsWith(curr_text_nr, "pseudo")){
      next
      # if it's a text block, though, assign word frequencies from csv
    } else {
      #print(curr_text_nr) # uncomment this if you'd like to show the texts each participant read

      # get word frequencies for current text nr
      curr_word_freqs <- subset(word_freqs_df, text_nr == curr_text_nr)$word_frequency

      # now this is where we do it differently than before: Remove the last value and add 1 NA
      # at idx = 1 of the vector, so the values are moved by 1 position.
      curr_word_freqs <- c(NA, curr_word_freqs[-length(curr_word_freqs)])

      # find out where in the subj_df text the text is located and add the word frequencies there
      subj_df[which(subj_df$text_nr == curr_text_nr & subj_df$question == ""),]$word_frequency_previous_word <- curr_word_freqs

      # Do the same for the surprisal scores:
      curr_surprisals <- subset(surprisal_df, text_nr == curr_text_nr)[ , c("surprisal_2_words_context", "entropy_2_words_context")]

      # add 1 NA to the start of the vectors, remove last value in each
      curr_surprisals <- rbind(c(NA, NA), curr_surprisals[-nrow(curr_surprisals), ])

      # find out where in the subj_df text the current text nr is located
      curr_row <- which(subj_df$text_nr == curr_text_nr & subj_df$question == "")

      # add the surprisal scores (untransformed & orthogonalized scores) there
      subj_df[curr_row, c("previous_surprisal_2", "previous_entropy_2")] <- curr_surprisals

    }# END if
  }# END loop texts
  
  ### CHANGE ORDER OF DATAFRAME ####
  # Move around the columns a bit:
  col_order <- c("participant", "nback_level", "block_nr_exp", "run_nr", "block_nr_run", "block_name",
                 "trial_nr", "text_nr", "word", "duration",
                 "colour", "target", "button_pressed", "nback_response", "nback_RT", "reaction",
                 "word_single", "word_length_single", "word_frequency", "Paced_RT",
                 "surprisal_2", "previous_surprisal_2", "word_frequency_previous_word", 
                 "previous_duration", "previous_reaction",
                 "session", "question", "chosen_ans", "ans_correct", "stop_word", "punctuation", "quotes", "date")

  subj_df <- subj_df[, col_order]
  
  ### GET PERFORMANCE MEASURES ####

  #### COMPREHENSION QUESTION PERFORMANCE ####
  
  # get question data:
  Q_df <- subset(subj_df, question != "")[,c("question", "chosen_ans", "ans_correct", "text_nr", "block_name", "participant")]

  Q_df$ans_correct <- as.logical(Q_df$ans_correct)
  
  # calculate accuracy per text
  Q_df <- Q_df %>% 
   group_by(text_nr) %>% 
    mutate(question_acc = sum(ans_correct[ans_correct == TRUE])/3)
  
  Q_subset <- Q_df %>% 
    select(c(text_nr, question_acc)) %>% 
    distinct

  # append Q_subset to bigger df for all participants
  df_comprehension_Qs <- as.data.frame(rbind(df_comprehension_Qs, Q_df))
  
  # append overall accuracy per text to subject df
  subj_df <- full_join(subj_df, Q_subset) %>% 
    select(-c(question, chosen_ans, ans_correct)) %>% 
    filter(!is.na(duration))


  ### N-BACK PERFORMANCE ####

  # set all durations in n-back trials without response to NA
  subj_df[which(subj_df$reaction == F), ]$nback_RT <- NA

  # create vector of n-back blocks in experiment
  nback_block_names <- subj_df %>% 
    filter(str_detect(nback_level, "^1") | str_detect(nback_level, "^2")) %>% 
    distinct(block_nr_exp) %>% 
    pull(block_nr_exp)

  # append empty d-prime column to df:
  subj_df$dprime <- c(rep(NA, times = length(subj_df$word)))

  # loop block names:
  for (nback_block in nback_block_names){

    # get data for current block
    curr_block <- subset(subj_df, block_nr_exp == nback_block)

    # remove trials where the RT was way too fast
    # (= participant reacted by accident)
    curr_block <- subset(curr_block, (nback_RT >= 100 | is.na(nback_RT)))

    # if there are still some trials left (let's say at least 5), compute d-prime
    if (length(curr_block$participant) > 5){
        # compute d-prime & add to bigger df
        d_prime <- get_dprime(curr_block$nback_response)
        subj_df$dprime[subj_df$block_nr_exp == nback_block] <- d_prime
    } # END if loop - check if there are still enough trials left
  }# END loop - compute d-primes
  
  # We'll use the mean d-prime from 1-back and 2-back single task main blocks
  # as a working memory measure for each participant. So get mean & append it as a new column to the df.
  subj_df$mean_dprime_singletasks <- mean(c(unique(subj_df[which(subj_df$block_name =="1back_single_main_no_click"),]$dprime),
                                            unique(subj_df[which(subj_df$nback_level =="2back_single_main_no_click"),]$dprime)))
  
  ### MARK PARTICIPANTS/BLOCKS FOR EXCLUSION:

  # append "empty" exclude trial / exclude participant columns to df
  subj_df$excl_trial       <- FALSE

  ### EXCLUDE SINGLE BLOCKS BASED ON COMPREHENSION QUESTION PERFORMANCE: ####
  
  # Idea: only exclude on block level, don't exclude full datasets because they messed up in 1 condition or so.
  # To identify these blocks, we look for a question accuracy of 0

  subj_df$excl_trial[subj_df$question_acc == 0] <- TRUE
  message(paste("excluded", length(subj_df[which(subj_df$question_acc == 0), "excl_trial"]), "trials because accuracy was 0%", sep = " "))
  
  ### EXCLUDE SINGLE BLOCKS BASED ON N-BACK TASK PERFORMANCE: ####

  # Check blocks with n-back tasks: 
  # Exclude block if the participant didn't do the n-back task (i.e. if they always/never pressed the target button).
  # We're excluding based on the d-prime values.
  # In the dual-task (main) blocks, we always had 50 targets & 250 non-targets. 
  # The d-prime for 0 hits and 0 false alarms is 0. If they always pressed the button and have 50 hits and 250 false alarms, the d-prime is also 0.
  # This means that they should have a d-prime above 0 if they at least attempted to do the task or below 0 if they attempted to do the 
  # task but did it the wrong way around (i.e.reacted if trial was a non-target trial and didn't react if trial was a target trial).
  
  # --> exclude all blocks with d-primes == 0.
  
  message(paste("excluded", length(subj_df[which(subj_df$dprime == 0), "excl_trial"]), "trials because d-prime was 0", sep = " "))
  subj_df[which(subj_df$dprime == 0), "excl_trial"] <- TRUE

  # append subj_df chunk to df_text_data where we collect the data of all participants we want to keep
  df_all_data <- as.data.frame(rbind(df_all_data, subj_df))

  message("------------------------")

}# END READ IN DATASETS

# exclude all trials that we marked for exclusion:
#df_all_data <- subset(df_all_data, excl_trial == FALSE)


# clean up!
#rm(list=ls()[! ls() %in% c("df_all_data", "df_comprehension_Qs", 
#                           "apatheme", "palet_load", 
#                           "palet_dprimes", "palet_dprimes_lines", 
#                           "palet_lab_online", "palet9", "today")])
```

# Add demographic data to dataframe
```{r}
# read in table with demographic data
df_demographics <- readxl::read_excel(here::here("Raw_data/EXNAT_3_Participants_backup.xlsx"))
df_demographics <- df_demographics[1:91,c("Subject", 
                                          "Age", 
                                          "Sex", 
                                          "RT_per_letter_baseline", 
                                          "RT_per_rect_1back_single", 
                                          "RT_per_rect_2back_single",
                                          "RT_per_letter_0back_dual",
                                          "RT_per_letter_1bck_dual",
                                          "RT_per_letter_2bck_dual",
                                          "MOCA",
                                          "DSST",
                                          "TMT-A",
                                          "TMT-B",
                                          "Reading_span")]
df_demographics <- df_demographics %>% 
  rename(participant = Subject,
         age = Age,
         sex = Sex)

df_all_data <- full_join(df_all_data, df_demographics)
exp_all_data <- df_all_data
```


# Save raw data in folder "RData"
```{r save raw data, echo = FALSE}
# save df
save(exp_all_data, file = here::here("RData/exp_all_data.RData"))

# save comp question df
save(df_comprehension_Qs, file = here::here("RData/exp_df_comprehension_questions.RData"))
```

# Find & exclude outliers using z-sqrt-POMS-transformation
# do not run until final transformation method is decided upon
```{r find and exclude outlier trials, echo = FALSE}
# DOESN'T SEEM TO BE A VERY VALID APPROACH WITH PACED DURATIONS SINCE THEY ARE ALREADY VERY MUCH FOCUSED ON THE INDIVIDUAL'S PERFORMANCE. I BELIEVE WE MIGHT NOT HAVE TO EXCLUDE ANY OUTLIERS AT ALL IN THE PACED BLOCKS SINCE TECHNICALLY OUTLIERS ARE NOT A THING ANYMORE.

# only use data from the main blocks from now on:
df_text_data_clean <- subset(df_all_data, block_name == "Reading_Baseline_main_no_click" | block_name == "Reading_pseudotext_no_click" | block_name == "1back_dual_main_no_click" | block_name == "2back_dual_main_no_click")

message("Nr of trials before exclusion of trials: ", length(df_text_data_clean$participant))

### EXCLUDE BREAKS ####
# --> Exclude all trials where participants took more than 5 seconds (arbitrary value)
# It's also a sanity check since this shouldn't be possible in EXNAT-3 due to introduced time-out values on trial basis
message(paste(length(subset(df_text_data_clean, duration > 5000)$ID), " trials containing breaks were excluded from further analysis", sep = ""))

df_text_data_clean <- subset(df_text_data_clean, duration <= 5000)


# Plot distribution of reading times 
densityplot(df_text_data_clean$duration)


### TRANSFORM RT DATA ####

# transf_val = sqrt (  ( x - sample_min ) / ( sample_max - sample_min)  )
# --> after this, z-transform all values and exclude all values exceeding a value of ± 2 (or ± 3, but they used 2 in the paper)

# This is basically a POMS (Little (2013), read in Moeller (2013)) transformation where you get
# the square root of the output afterwards and z-transform everything.

# Careful, normally, if you wanted to use the transformed values for group comparisons later, 
# you'd have to to the transformation across participants & conditions, so everything gets "pulled" into the same range.
# If you do this for each subject & condition separately, you can't compare means
# anymore, because every subset of data would have its own scale.

# Here, we only want to use the transformation for identifying & excluding outliers, so we don't really care about this problem. 
# So we can do this on block level, so we don't exclude more trials from "slower" 2-back blocks than from the BL for example.

# create new column in df_text_data_clean for the transformed RTs:
df_text_data_clean$tmp_transformed_RTs <- NA 

# get min reading time
# sample_min <- min(df_text_data$duration)
sample_min <- 0 # use smallest possible value here (this is described in a book by Little, 2013) - in this case: 0 words / 100 ms

# loop participants:
message("start excluding trials (block-wise)")
for (curr_id in unique(df_text_data_clean$participant)){
  
  message("current participant: ", curr_id)
  
  # create placeholders to count excluded trials / condition
  trials_excluded_BL    <- 0
  trials_excluded_1back <- 0
  trials_excluded_2back <- 0
  
  # get data of current participant:
  curr_df <- subset(df_text_data_clean, participant == curr_id)

  # loop blocks:
  for (curr_block in unique(curr_df$block_nr_exp)){
  
    # get data of current block:
    curr_block_data <- subset(curr_df, block_nr_exp == curr_block)

    # get max reading time (use sample maximum here)
    sample_max <- max(curr_block_data$duration)

    # do sqrt(POMS) transform of raw reading time values
    duration_standardized <- sqrt((curr_block_data$duration - sample_min) / (sample_max - sample_min))

    # z-transform reading data
    duration_standardized <- as.vector(scale(duration_standardized, center = T, scale = T))

    # put the transformed values into the big df with data of all participants:
    df_text_data_clean[which(df_text_data_clean$participant == curr_id & 
                             df_text_data_clean$block_nr_exp == curr_block), ]$tmp_transformed_RTs <- duration_standardized
    
    # check how many trials we have that are < -2 or > 2:
    trials_excluded <- length(which(duration_standardized > 3 | duration_standardized < -3))
  }# END LOOP BlOCKS
} # END LOOP PARTICIPANTS


# get index of all values < - 2 or > 2 & actually exclude those trials from the dataframe
excl_row_idx <- which(df_text_data_clean$tmp_transformed_RTs < -3 | df_text_data_clean$tmp_transformed_RTs > 3)

# check how the corresponding untransformed RTs look like so we get a feeling for what's being excluded:
# densityplot(df_text_data_clean[excl_row_idx, "duration"])

# kick out the outliers:
df_text_data_clean[excl_row_idx, "excl_trial"] <- TRUE
# total number of excluded trials
excl_trials <- sum(df_text_data_clean$excl_trial[df_text_data_clean$excl_trial == TRUE])
df_text_data_clean <- subset(df_text_data_clean, excl_trial == FALSE)

# drop column with the z-sqrt-POMS-transformed data, we don't need it anymore.  
df_text_data_clean$tmp_transformed_RTs <- NULL
```

# log-transform reading times
```{r log-transform reading times, echo = FALSE}
# Idea: Ignore that we just transformed our reading times for outlier exclusion. 
# We now take the raw reading times again and log-transform them.

# use natural logarithm (base e) here:
exp_all_data$reading_times_log <- log(exp_all_data$duration)
# to reverse the log transformation and get the data back to the original scale (for easier interpretation of the results), 
# use this: exp(log_transformed_data)

# plot the distribution: 
ggplot(exp_all_data, aes(x = duration)) +
  geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8) +
  theme_bw()
  #facet_wrap(~ block_name, nrow = 3)

ggplot(exp_all_data, aes(x = reading_times_log)) +
  geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.8) +
  theme_bw()

# make sure we update the values in the column previous_duration as well:
exp_all_data$previous_reading_times_log <- log(as.numeric(exp_all_data$previous_duration))

```

# Some renaming of columns
```{r}
# rename "block_kind" column 
names(exp_all_data)[which(names(exp_all_data) == "nback_level")] <- "cognitive_load"

# recode values in cognitive_load column
exp_all_data <- exp_all_data %>% 
  mutate(cognitive_load = case_when(
    str_detect(cognitive_load, "None") ~ "Reading only",
    str_detect(cognitive_load, "1") ~ "1-back",
    str_detect(cognitive_load, "2") ~ "2-back",
  ))

# turn the values into factors and set their order
exp_all_data$cognitive_load <- factor(exp_all_data$cognitive_load,
                                  levels = c("Reading only", "1-back", "2-back"))

# save df
save(exp_all_data, file = here::here("RData/exp_all_data.RData"))
```

# Plots
## Plot RTs by Task and Condition
```{r plot rt by task and cond}
plot_df <- subset(exp_all_data, reaction == F)

#---- RTs by Task and Condition ----
(plot_RT_task <- ggplot(plot_df, aes(x = cognitive_load, y = duration)) +
                      #geom_violinhalf(flip = c(1,3,5)) +
                      geom_boxplot() +
                      #geom_point2(plot_surprisal_df_summary, mapping = aes(x = Cognitive_Load, y = Reaction_time)) +
                      scale_color_manual(values = palet_task_condition_lines) +
                      scale_fill_manual(values = palet_task_condition) +
                      #facet_wrap(~ Surprisal_TS, ncol = 4) +
                      theme_classic(14)
                      #theme(legend.position = "none",
                      #      strip.background.x=element_rect(color = NA))
)
# save plot
cowplot::save_plot(plot_RT_task, file = here::here(paste0("Plots/RT_task_cond", today, ".pdf")))
```

## Plot RTs by Surprisal, Task & Condition (only dual-task blocks)
```{r plot RTs by Surprisal TS & Condition, message = FALSE, warning = FALSE}
plot_surprisal_df <- subset(exp_all_data, reaction == F) # exclude trials where you had a reaction

#---- Plot RTs by Surprisal x Cognitive Load ----
(plot_RT_surprisal_cond <- ggplot(plot_surprisal_df, aes(x = surprisal_2, y = duration, fill = cognitive_load, color = cognitive_load)) +
                      geom_smooth(method = lm, aes(fill = cognitive_load), na.rm = T) +
                      #geom_point2(plot_surprisal_df_summary, mapping = aes(x = Cognitive_Load, y = Reaction_time)) +
                      scale_color_manual(values = palet_load) +
                      scale_fill_manual(values = palet_load) +
                      scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +
                      #facet_wrap(~ Surprisal_TS, ncol = 4) +
                      theme_classic(14) +
                      theme(legend.position = "bottom",
                            strip.background.x=element_rect(color = NA))
)
```


## Plot Accuracy data
d-primes and comprehension questions by Task and Condition
Hint: We didn't have an n-back task in the baseline condition, so we can only compute & plot them for the 1-back and 2-back dual- and single-task blocks.
```{r plot d-primes by condition, age and location, echo = TRUE}
# get data, exclude BL because we didn't have an n-back task there
plot_df <- subset(exp_all_data, cognitive_load != "Reading only" )
plot_df <- droplevels(plot_df)

# get d-prime data:
# plot_df <- subset(df_text_data, block_kind == "1back_single_main" |
#                                 block_kind == "2back_single_main" |
#                                 block_kind == "1back_main" |
#                                 block_kind == "2back_main")

# aggregate by recording_location, age group, ID and cognitive load condition
plot_df <- setNames(aggregate(plot_df$dprime,
                              by = list(plot_df$participant, plot_df$cognitive_load),
                              FUN = mean),
                    c("participant", "Task", "Mean_dprime"))

# plot d-primes
(plot_dprimes <- ggplot(plot_df, aes(x = Task, 
                                    y = Mean_dprime), 
                            width = 4, height = 7) +
                      #geom_point(aes(color = Condition, fill = Condition), 
                      #       position = position_jitter(width = 0.04, height = 0),
                      #       alpha = 0.3,
                      #       shape = 19,
                      #       size = 1) +
                      #geom_violinhalf(flip = c(1,3)) +
                      geom_boxplot() +
                      scale_color_manual(values = palet_dprimes_lines) +
                      scale_fill_manual(values = palet_dprimes) +
                      theme_classic(14) +
                      theme(legend.position=("bottom"))+
                      coord_cartesian(ylim = c(0, 5))
)
cowplot::save_plot(plot_dprimes, file = here::here(paste0("Plots/dprimes_", today, ".pdf")))

## plot comprehension question performance
plot_df <- exp_all_data

# aggregate by recording_location, age, ID and cognitive load condition
plot_df <- setNames(aggregate(plot_df$question_acc,
                              by = list(plot_df$participant, plot_df$cognitive_load),
                              FUN = mean, na.rm = T),
                    c("participant", "Task", "Mean_percent_correct"))

# calculate percentage
plot_df$Mean_percent_correct <- plot_df$Mean_percent_correct * 100

# plot % correct by condition & age
(plot_comprehensionQs <- ggplot(plot_df,
                               aes(x = Task, 
                                   y = Mean_percent_correct)) +
                         geom_violinhalf() +
                         geom_jitter2(mapping = aes(group = participant), width = 0.2) +
                         scale_color_manual(values = palet_task_condition_lines) +
                         scale_fill_manual(values = palet_task_condition) +
                         # scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
                         theme_classic(14) +
                         #coord_cartesian(ylim = c(0, 1),
                        #                xlim = c(18, 85)) +
                         theme(legend.position = "bottom")
)
```  

# Stats
## Prepare data for LMMs
```{r prepare stats, echo = FALSE}
# shrink the df a bit: exclude rows that don't have surprisal scores on all time scales
#lmm_df <- subset(exp_all_data, !is.na(surprisal_2))

# only use data from the reading blocks from now on:
lmm_df <- subset(exp_all_data, str_detect(block_name, "Reading") |
                               str_detect(block_name, "dual"))
lmm_df <- droplevels(lmm_df)

# create a Simple Coding scheme for the variable cognitive_load
c <- contr.treatment(3) # create dummy coding scheme
my.coding <- matrix(rep(1/3, 6), ncol = 2) # make matrix with only 1/3 values
my.simple <- c-my.coding

#assign the new coding scheme to lmm_df$cognitive_load
contrasts(lmm_df$cognitive_load) <- my.simple

# typecast reaction as factor
lmm_df$reaction <- as.factor(lmm_df$reaction)

# typecast word_length_single, block_nr, trial_nr & age to numeric, and ID & text_nr to factor
lmm_df$word_length_single <- as.numeric(lmm_df$word_length_single)
lmm_df$trial_nr <- as.numeric(lmm_df$trial_nr)
lmm_df$block_nr_exp <- as.numeric(lmm_df$block_nr_exp)
lmm_df$run_nr <- as.numeric(lmm_df$run_nr)
lmm_df$age <- as.numeric(lmm_df$age)
lmm_df$participant <- as.factor(lmm_df$participant)
lmm_df$MOCA <- as.numeric(lmm_df$MOCA)

# ----------- Fix missing d-prime data in BL block -----------
# Problem: I can't include a predictor that doesn't have any data in one of the groups. 
# But I don't have any d-primes for the BL condition because there was no n-back 
# in those blocks, so I have 2 options: Invent data for the BL block & be careful with interpretation, or exclude the d-primes entirely from my model, which would be sad because I want to control for speed-accuracy tradeoff effects. 

# Idea: If d-prime is high, n-back accuracy is high and reading times should be slower.
# So in the BL condition with super fast reading, d-primes should be low if there was an imaginary n-back task in those blocks. 
# Idea: In order not to destroy the direction of the effect, use participant-level mean of all d-primes a constant in all BL blocks.
# We basically fit a regression line for the effect, which will go through the mean in any way, right? So use the mean as the constant for BL.

# try using participant-level mean of d-primes in 1-back and 2-back blocks as constant

# loop participants in lmm_df, get mean d-prime and assign it as constant: 
for (curr_id in unique(lmm_df$ID)){
  
  # get data of current participant
  curr_participant <- subset(lmm_df, ID == curr_id)
  
  # get mean d-prime from all blocks where we don't have NAs (which are the 1-back and 2-back blocks)
  mean_dprime <- mean(curr_participant$dprime, na.rm = T)
  
  # assign mean d-prime as constant in the BL blocks:
  lmm_df[which(lmm_df$ID == curr_id & lmm_df$cognitive_load == "BL"), ]$dprime <- mean_dprime
}

# check if we still have NAs somewhere:
#which(is.na(subset(lmm_df, cognitive_load == "BL")$dprime))


# ----------- prepare columns to check for speed accuracy tradeoff effects -----------

# Further ideas concerning speed accuracy tradeoffs:

# Single participants could perform worse in the n-back than others, so we should have 1 mean d-prime value for each participant.
# Likewise it is possible that participants perform differently in different blocks, 
# e.g. they put more effort into doing the n-back in block 1 and then not so much anymore in block 2. So we also need d-primes on block-level.
# To get rid of the participant-level effect, we need to subtract the mean from each block-wise d-prime though. 
# So what we're doing now is creating 2 new columns with d-prime values: 
# 1. a mean d-prime for each participant
# 2. the deviation of each d-prime from the participant's mean for each block

# 1. calculate mean d-prime for each participant
#lmm_df$dprime_mean <- ave(lmm_df$dprime, lmm_df$ID, FUN = function(x) mean(x, na.rm = TRUE))

# 2. subtract participant mean from each block's original d-prime
#lmm_df$dprime_diff <- lmm_df$dprime - lmm_df$dprime_mean


# 1. calculate mean %correct score for each participant
lmm_df$question_acc <- lmm_df$question_acc*100

# calculate mean per participant
lmm_df <- lmm_df %>% 
  group_by(participant) %>% 
  mutate(question_acc_mean = mean(question_acc, na.rm = T)) 

# 2. subtract participant mean from each block's original %correct score
lmm_df$question_acc_diff <- lmm_df$question_acc - lmm_df$question_acc_mean


# ----------- z-transform continuous variables for mixed models -----------

# Define columns you want to z-transform:

# z-transform: now you can compare the estimates in the lmm output
# only center, not z-transform: units stay the same, makes the interpretation of estimates easier, but you can't compare the estimates anymore.
#--> you could run the models twice, once with z-transformed values (for comparison of effects), once with centered values (for interpretation of single effects)
freq_length_cols <- c("word_frequency", "word_length_single", 
                      "dprime", #"dprime_mean", "dprime_diff", 
                      "previous_reading_times_log",
                      "question_acc", "question_acc_mean", 
                      "question_acc_diff", 
                      "mean_dprime_singletasks",
                      "age")
surprisal_cols   <- c("surprisal_2", "previous_surprisal_2") #  "entropy_2", "previous_entropy_2"

# Apply scale function to each column
# --> set center to TRUE to subtract the sample mean from each value, set scale to TRUE to divide by standard deviation
# --> make sure to convert the data to vector format before adding them as a new column
lmm_df[paste0(freq_length_cols, "_z")] <- lapply(lmm_df[freq_length_cols], 
                                                 function(x) as.vector(scale(x, 
                                                                             center = TRUE, 
                                                                             scale = TRUE)))
lmm_df[paste0(surprisal_cols, "_z")] <- lapply(lmm_df[surprisal_cols], 
                                               function(x) as.vector(scale(x, 
                                                                           center = TRUE, 
                                                                           scale = TRUE)))

lmm_df[paste0(freq_length_cols, "_centered")] <- lapply(lmm_df[freq_length_cols], 
                                                        function(x) as.vector(scale(x, 
                                                                                    center = TRUE, 
                                                                                    scale = FALSE)))
lmm_df[paste0(surprisal_cols, "_centered")] <- lapply(lmm_df[surprisal_cols], 
                                                      function(x) as.vector(scale(x, 
                                                                                  center = TRUE, 
                                                                                  scale = FALSE)))

```


## save data
```{r save lmm_df, echo = FALSE}

# save df
save(lmm_df, file = here::here("RData/lmm_df_all_subjects_02_25.RData"))
```

## Linear Mixed Model for log-transformed RT
```{r}
m_RT_ts2_age_centered_random_slope <- lmer(log(duration) ~ # control carry-over effects from previous trials:
                                                           previous_reading_times_log_centered +
                                                           # control diff. response strategies 
                                                           # on block- and participant-level:
                                                           dprime_centered + 
                                                           mean_dprime_singletasks_centered +
                                                           question_acc_mean_centered +
                                                           question_acc_diff_centered + 
                                                           # properties of words: 
                                                           word_frequency_centered + 
                                                           word_length_single_centered +
                                                           # was there an n-back response in the trial?
                                                           reaction + 
                                                           # position of trial in experiment for 
                                                           # controlling training & tiredness effects:
                                                           block_nr_exp + trial_nr +
                                                           # cognitive scores
                                                           #scale(MOCA, scale = FALSE) +
                                                           #DSST +
                                                           #Reading_span +
                                                           # Surprisal on TS 1, age & cognitive load condition:
                                                           # main effects & their 2-way and 3-way interactions 
                                                           surprisal_2_centered * age_centered * cognitive_load + 
                                                           # subject-specific random slope of cognitive load:
                                                           # cognitive load could have different 
                                                           # effects on different participants
                                                           (1 + cognitive_load | participant) + 
                                                           # random slopes for text, word and colour, 
                                                           # because we picked them "randomly" from a 
                                                           # billion of possible other texts, words and colours
                                                           (1 | text_nr) + 
                                                           (1 | word) + 
                                                           (1 | colour), 
                                                           data = lmm_df, REML = TRUE, 
                                                           lmerControl(optimizer = "bobyqa"))

#--- model with entropy scores ----
# performs better and should be our new model
m_RT_ts2_age_centered_random_slope_entropy <- lmer(log(duration) ~ # control carry-over effects from previous trials:
                                                           previous_reading_times_log_centered +
                                                           # control diff. response strategies 
                                                           # on block- and participant-level:
                                                           dprime_centered + 
                                                           mean_dprime_singletasks_centered +
                                                           compr_Qs_percent_correct_mean_centered +
                                                           compr_Qs_percent_correct_diff_centered + 
                                                           # lab vs. online:
                                                           recording_location + 
                                                           # properties of words: 
                                                           word_frequency_centered + 
                                                           word_length_single_centered +
                                                           # was there an n-back response in the trial?
                                                           reaction + 
                                                           # position of trial in experiment for 
                                                           # controlling training & tiredness effects:
                                                           block_nr + trial_nr +
                                                           # entropy
                                                           entropy_2_centered + 
                                                           # Surprisal on TS 1, age & cognitive load condition:
                                                           # main effects & their 2-way and 3-way interactions 
                                                           surprisal_2_centered * age_centered * cognitive_load + 
                                                           # subject-specific random slope of cognitive load:
                                                           # cognitive load could have different 
                                                           # effects on different participants
                                                           (1 + cognitive_load | ID) + 
                                                           # random slopes for text, word and colour, 
                                                           # because we picked them "randomly" from a 
                                                           # billion of possible other texts, words and colours
                                                           (1 | text_nr) + 
                                                           (1 | word) + 
                                                           (1 | colour), 
                                                           data = lmm_df, REML = TRUE, 
                                                           # choose bobyqa optimizer 
                                                           # (= Bound Optimization BY Quadratic Approximation) 
                                                           # for estimating model parameters. 
                                                           # It's efficient (= good for large datasets & 
                                                           # complex models) and relatively conservative.
                                                           lmerControl(optimizer = "bobyqa"))

# save model output:
saveRDS(m_RT_ts2_age_centered_random_slope_entropy, 
        file = "Analysis/RData/Mixed_models/m_RT_ts2_age_centered_random_slope_entropy.rds")

# Compare models
anova(m_RT_ts2_age_centered_random_slope, m_RT_ts2_age_centered_random_slope_entropy) # The model with entropy is better than the one without

## also run a version without mean-centering age for Johnson Neyman plots
m_RT_ts2_No_centering_age <- lmer(log(duration) ~ previous_reading_times_log_centered + 
                                                  dprime_centered + 
                                                  mean_dprime_singletasks_centered + 
                                                  compr_Qs_percent_correct_mean_centered +
                                                  compr_Qs_percent_correct_diff_centered + 
                                                  recording_location + word_frequency_centered +
                                                  word_length_single_centered + reaction + 
                                                  block_nr + trial_nr + 
                                                  entropy_2_centered +
                                                  surprisal_2_centered * age * cognitive_load + 
                                                  (1 + cognitive_load | ID) + (1 | text_nr) + 
                                                  (1 | word) + (1 | colour), 
                                                  data = lmm_df, REML = TRUE, lmerControl(optimizer = "bobyqa"))
saveRDS(m_RT_ts2_No_centering_age, 
        file = "Analysis/RData/Mixed_models/m_RT_ts2_No_centering_age_random_slope_entropy.rds")

#---- Comparing 1-back to 2-back and not only to reading baseline via post-hoc test ----
test_predictions(m_RT_ts2_age_centered_random_slope_entropy, terms = "cognitive_load [1back, 2back]")

# plotting the difference
pred <- predict_response(m_RT_ts2_age_centered_random_slope_entropy, terms = "cognitive_load [1back, 2back]")
plot(pred)
```
