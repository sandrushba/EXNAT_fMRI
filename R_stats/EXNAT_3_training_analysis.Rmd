---
title: "EXNAT_3 Training Analysis"
author: "Sandra Martin"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r file setup, echo = FALSE}
rm(list = ls()) # clear environment
knitr::opts_chunk$set() # set default options for all code blocks in this document
options(scipen = 999) # don't use scientific notation for very large or small numbers
```

# Load packages
```{r packages, echo = FALSE, message = FALSE, warning = TRUE}
# Create a list with needed libraries
pkgs <- c("here", # for working with relative paths
          "ggeffects", # create data frames of marginal effects for 'ggplot' from model outputs
          "stringr", # for getting substrings
          "ggplot2", # for plots
          "dplyr", # for replacing multiple values in vector with different values
          "reshape2", # for reshaping df format
          "tidyverse", # for aggregating
          "psycho", # for computing d-prime values
          "yarrr", # for plotting
          "devtools", # for getting packages from github
          "lattice", # for quick & dirty density plots
          "gtools", # for getting tuples from list
          "see", # for plotting residuals of lme4 model
          "performance", # needed for plotting the lme4 model output summary
          "lme4", # also for linear mixed models, but no p-values in the summary
          "lmerTest", # extension of lme4 - for tab_model() for showing lme4 model results
          "modelsummary", # for printing model fit measures
          "car", # for basic Anova() function & aGSIFs (= basically weird adjusted VIFs)
          "sjPlot", # for running Anova & showing results in a HTML table in the Viewer
          "colorspace", # for beautiful and balanced color palettes
          "interactions") # for simple slopes analysis


# Load each listed library, check if it's already installed
# and install if necessary
for (pkg in pkgs){
  if(!require(pkg, character.only = TRUE)){
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}

# install package with lists of stop words from github
devtools::install_github("quanteda/stopwords")
library(stopwords)
```

# Load d-prime function from different R script:
```{r source d-prime function, echo = FALSE}
source(here::here("get_dprime.R")) # get script
```

# Load df from RData
```{r}
# df cleaned from outliers and without n-back tasks
#load(here::here("RData/df_all_data.RData"))
```


# Settings for plots
# reload after reading in data, since environment values get deleted. You need the settings for the plots later on
```{r Theme for plots, echo = FALSE}
apatheme <- theme_bw()+
  theme(plot.title = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        axis.line = element_line(),
        text = element_text(family = 'sans',size = 14)) #panel.grid.major=element_blank(),

today <- Sys.Date()
today <- format(today, format="%y%m%d")


# Custom colour palettes for the plots:

# for distinguishing between paced and unpaced task:
palet_task_condition <- c("#D2BFE7",
                      "#977FB2") 
palet_task_condition_lines <- c("#ad8bd3",
                      "#7B5EC6") 

# for distinguishing between cognitive load conditions: 
# palet_load <- c("#575A7B", # Reading Only
#                 "#ED9201", # 1-back
#                 "#982126") # 2-back
palet_load <- c("#4B201D", "#9F4D48", "#F8A29E")

# for distinguishing between n-back tasks (single- & dual 1- and 2-back)
palet_dprimes = c("#ED9201", # 1-back Dual
                  "#fec160", # 1-back Single
                  "#982126", # 2-back Dual
                  "#d95459") # 2-back Single
palet_dprimes_lines = c("#cb7d00", # 1-back Dual
                        "#ED9201", # 1-back Single
                        "#982126", # 2-back Dual
                        "#d95459") # 2-back Single

# for simple slopes plots:
palet_simple_slopes = c("#585858", # n.s.
                        "#0c6ae8") # sign.

# For effects we don't really have colours for. Like age or surprisal.
palet_effects <- c("#365464") 

```


# Set path to datasets
```{r path setup, echo = FALSE}
path_data_folder <- here::here("Raw_data/training/")
```

# Read in data & do preprocessing on participant-level
In this chunk, we read in every dataset individually, compute reading times, reading speed, d-primes, comprehension question performance, and so on, 
add a few information on the words we used (e.g. surprisal scores on our 4 time scales, word frequencies, word lengths, punctuation,...), 
and then we exclude data on block level:
We only exclude data on block-level if performance measures indicate they didn't do the task(s) correctly.

```{r Read in data, message=FALSE, echo=TRUE, include=FALSE}
# Get list of all .csv files in the data folder
file_list <- list.files(path = path_data_folder, pattern='.csv')

# Placeholders df for demographics, questions & text data
df_all_data        <- data.frame()
df_comprehension_Qs <- data.frame()
#subj_demographics <- data.frame()

# Loop files in my file list aka directory
for (i in 1:length(file_list)) {

  # PREPARE FILE FOR PREPROCESSING
  # Read in current file
  subj_df <- read.csv(paste(path_data_folder, file_list[i],sep = ""), sep = "\t")

  # If the df is separated by a semicolon instead of a comma, we only get
  # one messed-up column. In this case, use semicolon as separator for csv:
  if (ncol(subj_df) == 1) {
    subj_df <- read.csv(paste(path_data_folder, file_list[i],sep = ""), sep = ",")
  }
  
  id <- subj_df$participant[i]
  
  # print message
  message(paste(i, " - Reading in file ", file_list[i], ", participant ID: ", id, sep = ""))

  # add column with info on whether participant should be excluded
  excl <- FALSE
  
  # rename block_kind column
  subj_df <- subj_df %>% 
    rename(nback_level = block_kind)
  
  #create new columns for demographics and education answers and fill them with the corresponding answers
  subj_df$gender <- NA 
  subj_df$age <- NA
  subj_df$language <- NA
  subj_df$dyslexia <- NA
  subj_df$vision_glasses <- NA
  subj_df$vision_lenses <- NA
  subj_df$handedness <- NA
  subj_df$education <- NA
  subj_df$edu_years <- NA
  subj_df$edu_profession <- NA
  
  subj_df$gender <- subj_df$demographic_form.response[4]
  subj_df$age <- subj_df$demographic_form.response[5]
  subj_df$language <- subj_df$demographic_form.response[6]
  subj_df$dyslexia <- subj_df$demographic_form.response[7]
  subj_df$vision_glasses <- subj_df$demographic_form.response[8]
  subj_df$vision_lenses <- subj_df$demographic_form.response[9]
  subj_df$handedness <- subj_df$demographic_form.response[10]
  subj_df$education <- subj_df$edu_form.response[13]
  subj_df$edu_profession <- subj_df$edu_form.response[21]
  
  #demographics <- subj_df[,c("participant", "gender", "age", "language", "dyslexia", "vision_glasses", "vision_lenses", "handedness", "education", "edu_profession", "edu_years")]
  #subj_demographics[i] <- demographics

  # replace , with . to conform with standard numeric format
  subj_df$edu_form.response <- gsub(",", ".", subj_df$edu_form.response)

  # extract number including decimal
  subj_df$edu_years <- sapply(subj_df$edu_form.response, function(x) str_extract(x, "\\d+(\\.\\d+)?"))

  # convert to numeric
  subj_df$edu_years <- as.numeric(subj_df$edu_years)

  # get the total sum and replace 'edu_years' with that sum
  total_sum <- sum(subj_df$edu_years, na.rm = TRUE)
  subj_df$edu_years <- total_sum


  # GET RAW TEXT & N-BACK DATA
  subj_df <- subset(subj_df, select=c(colour, target, nback_response, nback_RT, duration, text_nr, trial_nr, block_nr, block_name, nback_level, word, question, chosen_ans, ans_correct, RT_per_letter_baseline, RT_per_letter_1bck, RT_per_letter_2bck, participant, date, gender, age, language, dyslexia, vision_glasses, vision_lenses, handedness, education, edu_profession, edu_years))
  #took "session" out of the dataframe because there is no corresponding variable in the csv-file

  # get rid of all training blocks
  subj_df <- filter(subj_df, !str_detect(block_name, 'training') & block_name != "") 
  
  ### ADD NUMBERED BLOCK NAMES ####

  # We have each main block twice, but I would like to exclude outliers by block and not by condition.
  # Reason: Reading times in second block might be slightly different than in first block, so don't mix them up.
  
  change_df <- subj_df %>% 
    filter(!is.na(trial_nr)) %>% 
    group_by(block_name, block_nr) %>% 
    count() %>% 
    ungroup() %>% 
    group_by(block_name) %>% 
    mutate(Index=1:n()) %>% 
    mutate(block_names_numbered = paste(block_name, Index, sep = "_")) %>% 
    select(-c(Index, n))
  
  subj_df <- full_join(subj_df, change_df)


  ### MERGE INFO ON RT PER LETTER INTO ONE COLUMN ####
  subset_df <- subj_df %>% 
    select(c(block_name, starts_with("RT_per_letter"))) %>% 
    mutate(RT_per_letter = case_when(
      block_name == "Reading_Baseline_main_no_click" ~ RT_per_letter_baseline[!is.na(subj_df$RT_per_letter_baseline)][1],
      block_name == "1back_dual_main_no_click" ~ RT_per_letter_1bck[!is.na(subj_df$RT_per_letter_1bck)][1],
      block_name == "2back_dual_main_no_click" ~ RT_per_letter_2bck[!is.na(subj_df$RT_per_letter_2bck)][1]
    )) %>% 
    select(c(block_name, RT_per_letter)) %>% 
    distinct()
  
  subj_df <- full_join(subj_df, subset_df)
  
  ### CREATE COLUMN WHETHER condition was paced or unpaced
  subj_df <- subj_df %>% 
    mutate(condition = case_when(
      str_detect(block_name, "no_click") ~ "paced",
      TRUE ~ "self-paced"
    ))
  
  
  # GET ADDITIONAL INFORMATION ON THE TEXTS:

  ### PUNCTUATION ####

  # Edit the texts a bit. Currently, we have words & punctuation
  # mixed up. Would be nice if we had one word column
  # and some others with info on punctuation.

  punctuation <- c(rep("", times = length(subj_df$participant)))

  # get all .
  punctuation[grep("[.]", subj_df$word)] <- "point"
  # get all ?
  punctuation[grep("[?]", subj_df$word)] <- "question_mark"
  # get all !
  punctuation[grep("[!]", subj_df$word)] <- "exclamation_mark"
  # get all ,
  punctuation[grep("[,]", subj_df$word)] <- "comma"
  # get all ;
  punctuation[grep("[;]", subj_df$word)] <- "semicolon"
  # get all :
  punctuation[grep("[:]", subj_df$word)] <- "colon"

  # get all "
  # This is tricky for various reasons:

  # 1. there could be quotes directly after or
  # before a point for example

  # Idea: Separate column for quotes
  quotes <- c(rep("", times = length(subj_df$participant)))

  # 2. I want to differentiate between opening and closing quotes,
  # but they look the same.

  # Idea: make them all "opening quotes" and change every second one to
  # "closing_quote". This should do the trick.
  quotes[grep("\"", subj_df$word)] <- "opening_quote"
  opening <- TRUE

  # loop list of quotes
  for (x in 1:length(quotes)){
    # get current value in vector "quotes" & current word
    curr_val  <- quotes[x]
    curr_word <- subj_df$word[x]

    if (curr_val == "opening_quote" & # if the current value is not empty
        opening == TRUE & # and we set "opening" to TRUE
        grepl("\"[A-Za-z0-9]+\"", curr_word) == FALSE){ # and there are not 2 quotes around the word

      # leave it as is, next quote is the closing one
      opening <- FALSE

      # if we have a quote, but it has to be a closing one, change it accordingly
    } else if (curr_val == "opening_quote" &
               opening == FALSE &
               grepl("\"[A-Za-z0-9]+\"", curr_word) == FALSE){
      # change value to closing quote
      quotes[x] <- "closing_quote"
      # next quote is the opening one
      opening <- TRUE
      # if it's a quote around a single word, mark as "both"
    } else if (curr_val == "opening_quote" &
               grepl("\"[A-Za-z0-9]+\"", curr_word) == TRUE){
      # change value to both
      quotes[x] <- "both"
    }
  }

  # remove all punctuation
  word_single <- gsub('[[:punct:] ]+',' ', subj_df$word)
  # "trim" away spaces before and after words
  word_single <- trimws(word_single, which = c("left"))
  word_single <- trimws(word_single, which = c("right"))
  # put dashes into spaces between words (words like "ice-cream" for example)
  word_single <- gsub(" ", "-", word_single, fixed = TRUE)

  # get word length for single words
  word_length_single <- nchar(word_single)


  ### N-BACK RESPONSES ####

  # check if we had an n-back reaction while the word was shown
  # create vector with only FALSEs
  reaction <- c(rep(FALSE, times = length(subj_df$participant)))
  # check where in subj_df we have responses (hit or false alarm) and change value in reaction vector to TRUE at that index
  reaction[which(subj_df$nback_response == "hit" | subj_df$nback_response == "false alarm")] <- TRUE

  # APPEND NEW COLUMNS
  # append punctuation and quotes column, column with words without punctuation
  # column with length of each the single words and reaction column as
  # additional columns to subj_df:
  subj_df <- data.frame(cbind(subj_df, word_single, punctuation,
                              quotes, word_length_single, reaction))

  ### STOP WORDS ####

  # Now also get previous reaction and stop words.
  # First, append empty columns to df:
  subj_df[, c("previous_reaction", "previous_duration", "stop_word")] <- ""

  # get list of German stop_words
  stop_words <- stopwords("de", source = "snowball")
  # snowball = stopwords list based on the Snowball stemmer's word lists.
  # --> https://snowballstem.org/texts/introduction.html

  # now loop rows and gradually fill in the empty columns.
  for (idx in 1:length(subj_df$participant)){
    # if it's the first trial of a new block, go to next iteration
    # because in this case we don't have previous data.
    # Also skip the following part if it's a block without text.
    if (subj_df$trial_nr[idx] > 1 && !is.na(subj_df$trial_nr[idx])){
      # fill in the missing data by getting the values from the previous trial:
      subj_df$previous_duration[idx]    <- subj_df$duration[idx-1]
      subj_df$previous_reaction[idx]    <- subj_df$reaction[idx-1]
    }

    if (subj_df$word_single[idx] %in% stop_words){
      # check if current word is a stop word or not
      subj_df$stop_word[idx] <- TRUE 
      }
    else {
      subj_df$stop_word[idx] <- FALSE
    }
  }
  
  ### WORD FREQUENCIES & SURPRISAL SCORES ####

  # Include word frequencies & surprisal scores for each word

  # append "empty" word frequency & surprisal score columns to df
  # to do so, create a vector of column names
  col_names <- c("word_frequency", paste0("surprisal_", c(2)))#,
                 #paste0("surprisal_", c(1, 2, 8, 16, 32), "_ortho"),
                 #paste0("similarity_", c(1, 2, 8, 16, 32)))
  # then add "empty" columns to data frame subj_df
  subj_df[, col_names] <- 0

  # get word frequency & surprisal scores for each word
  # load word freq df
  word_freqs_df = read.csv(here::here("word_frequencies/Word_freqs_training.csv"), sep = ",", header = TRUE)[2:4]
  word_freqs_df$text_nr <-  paste0("text_", sprintf("%02d", word_freqs_df$text_nr))
  # Explanation: We compute the word frequencies using another
  #              script which is called "calculate_word_frequencies.py".
  #              You can find it in the Analysis folder.
  #              --> word frequencies were taken from this python package:
  #              Speer, R., Chin, J., Lin, A., Jewett, S., & Nathan, L. (2018, October 3).
  #              LuminosoInsight/wordfreq: v2.2. Zenodo. https://doi.org/10.5281/zenodo.1443582

#--------------------------------------------------------------------------------------------------------------------------------
#surprisal scores will be included as soon as it is clear how to calculate them. Until then, only word frequency will be used
  # Load surprisal scores
  # load surprisal scores / similarity scores df with TS = context chunk size
  #surprisal_df = read.csv(here::here("surprisal scores/surprisal_scores_masked_context.csv"), sep = ",", header = TRUE)

  # Explanation: I computed the scores in Python using a German GPT-2 model. For each text you can select a context chunk of x words (e.g. 5 words)
  #              and predict the next word. For each possible continuation of your context, you get probabilities.
  #              If you get the probability for the actual word and compute the negative log of it, you have the surprisal score
  #              for your word on time scale x (e.g. 5 words = TS 5). The time scales are all highly correlated, which might be due to the fact that each
  #              time scale also includes context information from all lower timescales, so it's like a Russian doll situation.
  #              To deal with this problem, we masked all words that were already processed in lower time scales,
  #              so each time scale only uses the "new" parts of the input chunk.


  # loop individual texts
  for (curr_text_nr in unique(subj_df$text_nr)){

    # in some blocks we don't have texts, so skip those
    # CAVE: currently also skipping text 10 because I still need to calculate values for this text
    if (curr_text_nr == "" |
        str_detect(curr_text_nr, "pseudo") |
        (id == "MA01" & curr_text_nr == "text_05") |
         (id == "MA01" & curr_text_nr == "text_06") |
         (id == "MA01" & curr_text_nr == "text_07") |
         (id == "MA01" & curr_text_nr == "text_08")) {
      next
      # if it's a text block, though, assign word frequencies from csv
    } else {
      print(curr_text_nr) # uncomment this if you'd like to show the texts each participant read

      # get word frequencies for current text nr
      curr_word_freqs <- subset(word_freqs_df, text_nr == curr_text_nr)$Word.frequency
      # find out where in the subj_df text the text is located and add the word frequencies there
      subj_df[which(subj_df$text_nr == curr_text_nr & subj_df$question == ""),]$word_frequency <- curr_word_freqs

      # Do the same for the surprisal scores.
      #curr_surprisals <- subset(surprisal_df, text_nr == curr_text_nr)

      # find out where in the subj_df text the current text nr is located
      #curr_row <- which(subj_df$text_nr == curr_text_nr & subj_df$question == "")

      # add the surprisal scores (untransformed & orthogonalized scores) there
      #subj_df[curr_row, c("surprisal_1", "surprisal_4",
      #                    "surprisal_12", "surprisal_60")]  <- curr_surprisals[c("surprisal_1", "surprisal_4",
      #                                                                           "surprisal_12",  "surprisal_60")]
      #subj_df[curr_row, c("surprisal_1_ortho", "surprisal_2_ortho",
      #                    "surprisal_8_ortho", "surprisal_16_ortho",
      #                    "surprisal_32_ortho")]                     <- curr_surprisals[c("surprisal_1_ortho", "surprisal_2_ortho",
      #                                                                                    "surprisal_8_ortho", "surprisal_16_ortho",
      #                                                                                    "surprisal_32_ortho")]

    }# END if
  }# END loop texts

  
  ### GET SURPRISAL SCORES OF PREVIOUS WORD ####
  # EXCLUDED FOR NOW
  # --> basically do the same again as before, but add surprisal scores for current for to row of next word.

  # append "empty" word frequency & surprisal score columns to df
  # to do so, create a vector of column names
  #col_names <- c("word_frequency_previous_word", paste0("previous_surprisal_", c(2)))
  # then add "empty" columns to data frame subj_df
  #subj_df[, col_names] <- 0

  # loop individual texts
 # for (curr_text_nr in unique(subj_df$text_nr)){

    # in some blocks we don't have texts, so skip those
 #   if (curr_text_nr == "" | curr_text_nr == "text_10"){
 #     next
      # if it's a text block, though, assign word frequencies from csv
 #   } else {
      #print(curr_text_nr) # uncomment this if you'd like to show the texts each participant read

      # get word frequencies for current text nr
  #    curr_word_freqs <- subset(word_freqs_df, text_nr == curr_text_nr)$word_frequency

      # now this is where we do it differently than before: Remove the last value and add 1 NA
      # at idx = 1 of the vector, so the values are moved by 1 position.
 #     curr_word_freqs <- c(NA, curr_word_freqs[-length(curr_word_freqs)])

      # find out where in the subj_df text the text is located and add the word frequencies there
 #     subj_df[which(subj_df$text_nr == curr_text_nr & subj_df$question == ""),]$word_frequency_previous_word <- curr_word_freqs

      # Do the same for the surprisal scores:
  #    curr_surprisals <- subset(surprisal_df, text_nr == curr_text_nr)[ , c("surprisal_1", "surprisal_4",
  #                                                                          "surprisal_12", "surprisal_60")]

      # add 1 NA to the start of the vectors, remove last value in each
 #     curr_surprisals <- rbind(c(NA, NA, NA, NA), curr_surprisals[-nrow(curr_surprisals), ])

      # find out where in the subj_df text the current text nr is located
 #     curr_row <- which(subj_df$text_nr == curr_text_nr & subj_df$question == "")

      # add the surprisal scores (untransformed & orthogonalized scores) there
 #     subj_df[curr_row, c("previous_surprisal_1", "previous_surprisal_4",
 #                         "previous_surprisal_12","previous_surprisal_60")] <- curr_surprisals

#    }# END if
#  }# END loop texts

  ### CHANGE ORDER OF DATAFRAME ####
  # Move around the columns a bit:
  col_order <- c("participant", "nback_level", "condition", "block_nr", "block_names_numbered", "block_name",
                 "trial_nr", "text_nr", "word", "duration",
                 "colour", "target", "nback_response", "nback_RT", "reaction",
                 "word_single", "word_length_single", "word_frequency", "RT_per_letter",
             #    "surprisal_2", "previous_surprisal_2","word_frequency_previous_word", 
                 "previous_duration", "previous_reaction", "question", "chosen_ans", "ans_correct", "stop_word", "punctuation", "quotes", "date","gender", "age", "language", "dyslexia", "vision_glasses", "vision_lenses", "handedness", "education", "edu_profession", "edu_years")

  subj_df <- subj_df[, col_order]
  
  ### GET PERFORMANCE MEASURES ####

  #### COMPREHENSION QUESTION PERFORMANCE ####
  # Check the performance in the reading comprehension questions in the 2 baseline blocks:
  # If they don't have 3/3 in at least one of the blocks, exclude their data.

  # get question data:
  Q_df <- subset(subj_df, question != "")[,c("question", "chosen_ans", "ans_correct", "text_nr", "block_name", "condition", "participant")] # use block_name instead of n_back_level


  Q_df$ans_correct <- as.logical(Q_df$ans_correct)
  
  
  # calculate accuracy per text
  Q_df <- Q_df %>% 
    group_by(participant, text_nr, condition) %>% 
    mutate(question_acc = ifelse(condition == "unpaced", 
                                 sum(ans_correct[ans_correct == TRUE])/3, 
                                 ifelse(condition == "paced" & participant != "MA01", 
                                        sum(ans_correct[ans_correct == TRUE]), 
                                        sum(ans_correct[ans_correct == TRUE])/3)))

  
  Q_subset <- Q_df %>% 
    select(c(participant, condition, text_nr, question_acc)) %>% 
    distinct

  # append Q_subset to bigger df for all participants
  df_comprehension_Qs <- as.data.frame(rbind(df_comprehension_Qs, Q_df))
  
  # append overall accuracy per text to subject df
  subj_df <- full_join(subj_df, Q_subset) %>% 
    select(-c(question, chosen_ans, ans_correct)) %>% 
    filter(!is.na(duration))


  ### N-BACK PERFORMANCE ####

  # set all durations in n-back trials without response to NA
  subj_df[which(subj_df$reaction == F), ]$nback_RT <- NA
  
  # check n-back performance in each block:
  # create vector of n-back blocks in experiment
  nback_block_names <- subj_df %>% 
    filter(str_detect(block_names_numbered, "^1") | str_detect(block_names_numbered, "^2") | str_detect(block_names_numbered, "^0")) %>% 
    distinct(block_names_numbered) %>% 
    pull(block_names_numbered)

  # append empty d-prime column to df:
  subj_df$dprime <- c(rep(NA, times = length(subj_df$word)))

  # loop block names:
  for (nback_block in nback_block_names){

    # get data for current block
    curr_block <- subset(subj_df, block_names_numbered == nback_block)

    # remove trials where the RT was way too fast
    # (= participant reacted by accident)
    curr_block <- subset(curr_block, (nback_RT >= 100 | is.na(nback_RT)))

    # if there are still some trials left (let's say at least 5), compute d-prime
    if (length(curr_block$participant) > 5){
        # compute d-prime & add to bigger df
        d_prime <- get_dprime(curr_block$nback_response)
        subj_df$dprime[subj_df$block_names_numbered == nback_block] <- d_prime
    } # END if loop - check if there are still enough trials left
  }# END loop - compute d-primes
  
  # We'll use the mean d-prime from 1-back and 2-back single task main blocks
  # as a working memory measure for each participant. So get mean & append it as a new column to the df.
  subj_df$mean_dprime_singletasks <- mean(c(unique(subj_df[which(subj_df$nback_level =="1" & str_detect(subj_df$block_name, "single")),]$dprime),
                                            unique(subj_df[which(subj_df$nback_level =="2" & str_detect(subj_df$block_name, "single")),]$dprime)))
  
  ### MARK PARTICIPANTS/BLOCKS FOR EXCLUSION:

  # append "empty" exclude trial / exclude participant columns to df
  subj_df$excl_trial       <- FALSE

  ### EXCLUDE SINGLE BLOCKS BASED ON COMPREHENSION QUESTION PERFORMANCE: ####
  # IGNORE THIS FOR TRAINING FOR NOW
  # # Idea: only exclude on block level, don't exclude full datasets because they messed up in 1 condition or so.
  # # To identify these blocks, we look for a question qccuracy of 0
  # 
  # subj_df$excl_trial[subj_df$question_acc == 0] <- TRUE
  # message(paste("excluded", length(subj_df[which(subj_df$question_acc == 0), "excl_trial"]), "trials because accuracy was 0%", sep = " "))
  # 
  # ### EXCLUDE SINGLE BLOCKS BASED ON N-BACK TASK PERFORMANCE: ####
  # 
  # # Check blocks with n-back tasks: 
  # # Exclude block if the participant didn't do the n-back task (i.e. if they always/never pressed the target button).
  # # We're excluding based on the d-prime values.
  # # In the dual-task (main) blocks, we always had 50 targets & 250 non-targets. 
  # # The d-prime for 0 hits and 0 false alarms is 0. If they always pressed the button and have 50 hits and 250 false alarms, the d-prime is also 0.
  # # This means that they should have a d-prime above 0 if they at least attempted to do the task or below 0 if they attempted to do the 
  # # task but did it the wrong way around (i.e.reacted if trial was a non-target trial and didn't react if trial was a target trial).
  # 
  # # --> exclude all blocks with d-primes == 0.
  # 
  # message(paste("excluded", length(subj_df[which(subj_df$dprime == 0), "excl_trial"]), "trials because d-prime was 0", sep = " "))
  # subj_df[which(subj_df$dprime == 0), "excl_trial"] <- TRUE

  # append subj_df chunk to df_text_data where we collect the data of all participants we want to keep
  df_all_data <- as.data.frame(rbind(df_all_data, subj_df))

  message("------------------------")

}# END READ IN DATASETS

# exclude all trials that we marked for exclusion:
#df_all_data <- subset(df_all_data, excl_trial == FALSE)
df_all_data$age <- sapply(df_all_data$age, function(x) str_extract_all(x, "\\d+")[[1]])
df_all_data$age <- as.numeric(df_all_data$age)

training_all_data <- df_all_data

#demographics_df <- rbind(subj_demographics)

# clean up!
#rm(list=ls()[! ls() %in% c("df_all_data", "df_comprehension_Qs", 
#                           "apatheme", "palet_load", 
#                           "palet_dprimes", "palet_dprimes_lines", 
#                           "palet_lab_online", "palet9", "today")])
```

# Save raw data in folder "RData"
```{r save raw data, echo = FALSE}
# save df
save(training_all_data, file = here::here("RData/training_all_data.RData"))

# save comp question df
save(df_comprehension_Qs, file = here::here("RData/df_comprehension_questions.RData"))
```

# Separate demographic data
```{r}

df_demographics <- subset(df_all_data, select = c(participant, gender, age, language, dyslexia, vision_glasses, vision_lenses, handedness, education, edu_profession, edu_years))

save(df_demographics, file = here::here("RData/df_demographics.RData"))
```


# Find & exclude outliers using z-sqrt-POMS-transformation
#erstmal nicht mit ausführen - unklar, welche Methode verwendet werden wird
```{r find and exclude outlier trials, echo = FALSE}

# only use data from the main blocks from now on:
df_text_data_clean <- subset(df_all_data, block_name == "Reading_Baseline_main_click" | block_name == "Reading_Baseline_main_no_click" |
                               block_name == "1back_dual_main_click" | block_name == "1back_dual_main_no_click" |
                               block_name == "2back_dual_main_click" | block_name == "2back_dual_main_no_click")

message("Nr of trials before exclusion of trials: ", length(df_text_data_clean$participant))

### EXCLUDE BREAKS ####
# --> Exclude all trials where participants took more than 5 seconds (arbitrary value)
# It's also a sanity check since this shouldn't be possible in EXNAT-3 due to introduced time-out values on trial basis
message(paste(length(subset(df_text_data_clean, duration > 5000)$ID), " trials containing breaks were excluded from further analysis", sep = ""))

df_text_data_clean <- subset(df_text_data_clean, duration <= 5000)


# Plot distribution of reading times 
# densityplot(df_text_data_clean$duration)


### TRANSFORM RT DATA ####

# transf_val = sqrt (  ( x - sample_min ) / ( sample_max - sample_min)  )
# --> after this, z-transform all values and exclude all values exceeding a value of ± 2 (or ± 3, but they used 2 in the paper)

# This is basically a POMS (Little (2013), read in Moeller (2013)) transformation where you get
# the square root of the output afterwards and z-transform everything.

# Careful, normally, if you wanted to use the transformed values for group comparisons later, 
# you'd have to to the transformation across participants & conditions, so everything gets "pulled" into the same range.
# If you do this for each subject & condition separately, you can't compare means
# anymore, because every subset of data would have its own scale.

# Here, we only want to use the transformation for identifying & excluding outliers, so we don't really care about this problem. 
# So we can do this on block level, so we don't exclude more trials from "slower" 2-back blocks than from the BL for example.

# create new column in df_text_data_clean for the transformed RTs:
df_text_data_clean$tmp_transformed_RTs <- NA 

# get min reading time
# sample_min <- min(df_text_data$duration)
sample_min <- 0 # use smallest possible value here (this is described in a book by Little, 2013) - in this case: 0 words / 100 ms

# loop participants:
message("start excluding trials (block-wise)")
for (curr_id in unique(df_text_data_clean$participant)){
  
  message("current participant: ", curr_id)
  
  # create placeholders to count excluded trials / condition
  trials_excluded_BL    <- 0
  trials_excluded_1back <- 0
  trials_excluded_2back <- 0
  
  # get data of current participant:
  curr_df <- subset(df_text_data_clean, participant == curr_id)

  # loop blocks:
  for (curr_block in unique(curr_df$block_names_numbered)){
  
    # get data of current block:
    curr_block_data <- subset(curr_df, block_names_numbered == curr_block)

    # get max reading time (use sample maximum here)
    sample_max <- max(curr_block_data$duration)

    # do sqrt(POMS) transform of raw reading time values
    duration_standardized <- sqrt((curr_block_data$duration - sample_min) / (sample_max - sample_min))

    # z-transform reading data
    duration_standardized <- as.vector(scale(duration_standardized, center = T, scale = T))

    # put the transformed values into the big df with data of all participants:
    df_text_data_clean[which(df_text_data_clean$participant == curr_id & 
                             df_text_data_clean$block_names_numbered == curr_block), ]$tmp_transformed_RTs <- duration_standardized
    
    # check how many trials we have that are < -2 or > 2:
    trials_excluded <- length(which(duration_standardized > 2 | duration_standardized < -2))
  }# END LOOP BlOCKS
} # END LOOP PARTICIPANTS


# get index of all values < - 2 or > 2 & actually exclude those trials from the dataframe
excl_row_idx <- which(df_text_data_clean$tmp_transformed_RTs < -2 | df_text_data_clean$tmp_transformed_RTs > 2)

# check how the corresponding untransformed RTs look like so we get a feeling for what's being excluded:
# densityplot(df_text_data_clean[excl_row_idx, "duration"])

# kick out the outliers:
df_text_data_clean[excl_row_idx, "excl_trial"] <- TRUE
# total number of excluded trials
excl_trials <- sum(df_text_data_clean$excl_trial[df_text_data_clean$excl_trial == TRUE])
df_text_data_clean <- subset(df_text_data_clean, excl_trial == FALSE)

# drop column with the z-sqrt-POMS-transformed data, we don't need it anymore.  
df_text_data_clean$tmp_transformed_RTs <- NULL
```

# log-transform reading times
```{r log-transform reading times, echo = FALSE}
# Idea: Ignore that we just transformed our reading times for outlier exclusion. 
# We now take the raw reading times again and log-transform them.

#prepare data with dual and single task values
# use natural logarithm (base e) here:

df_all_data$reading_times_log <- log(df_all_data$duration)
# to reverse the log transformation and get the data back to the original scale (for easier interpretation of the results), 
# use this: exp(log_transformed_data)

# plot the distribution: 
#densityplot(df_text_data_dual$reading_times_log)
# make sure we update the values in the column previous_duration as well:
df_all_data$previous_reading_times_log <- log(as.numeric(df_all_data$previous_duration))

```

# Some renaming of columns
```{r}
# rename "block kind" column
names(df_all_data)[which(names(df_all_data) == "nback_level")] <- "cognitive_load"

# recode values in cognitive_load column
df_all_data <- df_all_data %>% 
  mutate(cognitive_load = case_when(
    str_detect(block_name, "Baseline") ~ "Reading only",
    str_detect(block_name, "1back_single") ~ "1-back-single",
    str_detect(block_name, "2back_single") ~ "2-back-single",
    str_detect(block_name, "0back_dual") ~ "0-back-dual",
    str_detect(block_name, "1back_dual") ~ "1-back-dual",
    str_detect(block_name, "2back_dual") ~ "2-back-dual",
    str_detect(block_name, "pseudotext") ~ "Pseudotext"
  ))
#1-back-single and 2-back-single in the paced condition are measured in seconds and not in milliseconds like the rest of the cognitive load tasks. They need to be changed to avoid issues with the units of the graphs later on

df_all_data<- df_all_data %>%
  group_by(participant, condition) %>%
  mutate(cognitive_load = as.character(cognitive_load),
         has_single = str_detect(cognitive_load, "1-back-single|2-back-single"),
         duration = ifelse(has_single & condition == "paced", duration * 1000, duration)) %>%
  ungroup()


# turn the values into factors and set their order
df_all_data$cognitive_load <- factor(df_all_data$cognitive_load,
                                  levels = c("Reading only", "1-back-single", "2-back-single", "0-back-dual", "1-back-dual", "2-back-dual", "Pseudotext"))

# save df
save(df_all_data, file = here::here("RData/df_all_data_all_subjects.RData"))
```


# Plots
## Plot RTs by Task and Condition
```{r plot rt by task and cond}
plot_df <- subset(df_all_data, reaction == F)

#---- RTs by Task and Condition ----
plot_RT_task_cond <- ggplot(plot_df, aes(x = cognitive_load, y = duration, fill = condition, color = condition)) +
                      #geom_violinhalf(flip = c(1,3,5)) +
                      geom_boxplot() +
                      #geom_point2(plot_surprisal_df_summary, mapping = aes(x = Cognitive_Load, y = Reaction_time)) +
                      scale_color_manual(values = palet_task_condition_lines) +
                      scale_fill_manual(values = palet_task_condition) +
                      #facet_wrap(~ Surprisal_TS, ncol = 4) +
                      theme_classic(14)+
                      #theme(legend.position = "none",
                      #      strip.background.x=element_rect(color = NA))
                      labs(x="Cognitive Load", y="Duration", title="Reading time per condition per task")
plot_RT_task_cond

# save plot
cowplot::save_plot(plot_RT_task_cond, file = here::here(paste0("Plots/RT_task_cond_", today, ".pdf")))
```

# all reading conditions reading time, dprimes and accuracy
## Plot Accuracy data
d-primes and comprehension questions by Task and Condition
Hint: We didn't have an n-back task in the baseline condition, so we can only compute & plot them for the 1-back and 2-back dual- and single-task blocks.
```{r}
#reading time for only the reading conditions
nback_cond <- c("Reading only","Pseudotext", "1-back-dual", "2-back-dual", "0-back-dual")
dual_plot_df <- df_all_data %>% 
  filter(cognitive_load %in% nback_cond)
dual_plot_df <- droplevels(dual_plot_df)

plot_reading_duration <- ggplot(dual_plot_df, aes(y=duration, color = cognitive_load, fill = cognitive_load, x=age))+
  geom_smooth(method = lm, aes(group = cognitive_load))+
  facet_wrap(~ condition)+
  theme_classic()
plot_reading_duration

cowplot::save_plot(plot_reading_duration, file = here::here(paste0("Plots/plot_reading_duration_",today, ".pdf")))

#------------------------------------------------------------------------------------

#reading time for all the conditions
nback_cond <- c("1-back-dual", "2-back-dual", "0-back-dual", "1-back-single", "2-back-single")
dual_plot_df <- df_all_data %>% 
  filter(cognitive_load %in% nback_cond)

plot_reading_duration_all <- ggplot(dual_plot_df, aes(y=duration, color = cognitive_load, fill = cognitive_load, x=age, group = cognitive_load))+
  geom_smooth(method = lm)+
  facet_wrap(~ condition)+
  theme_classic()
plot_reading_duration_all
cowplot::save_plot(plot_reading_duration_all, file = here::here(paste0("Plots/plot_reading_duration_all_",today, ".pdf")))
#------------------------------------------------------------------------------------

#dprimes for the dual conditions
nback_cond <- c("1-back-dual", "2-back-dual", "0-back-dual")
dual_plot_df <- df_all_data %>% 
  filter(cognitive_load %in% nback_cond)
dual_plot_df <- setNames(aggregate(dual_plot_df$dprime,
                              by = list(dual_plot_df$participant, dual_plot_df$condition, dual_plot_df$cognitive_load),
                              FUN = mean),
                    c("participant", "Task", "Condition", "Mean_dprime"))

# plot d-primes

plot_dprimes_dual <- ggplot(dual_plot_df, aes(x = Condition, 
                                    y = Mean_dprime, 
                               fill = Task,
                               color = Task), 
                            width = 4, height = 7) +
                      #geom_point(aes(color = Condition, fill = Condition), 
                      #       position = position_jitter(width = 0.04, height = 0),
                      #       alpha = 0.3,
                      #       shape = 19,
                      #       size = 1) +
                      #geom_violinhalf(flip = c(1,3)) +
                      geom_boxplot() +
                      scale_color_manual(values = palet_dprimes_lines) +
                      scale_fill_manual(values = palet_dprimes) +
                      theme_classic(14) +
                      theme(legend.position=("bottom"))+
                      coord_cartesian(ylim = c(0, 5))+
                      labs(y="Mean dprime", title="Mean dprime score per task per condition")
#this plot only has the dual task condition, but we want one that has both
plot(plot_dprimes_dual)
cowplot::save_plot(plot_dprimes_dual, file = here::here(paste0("Plots/dprimes_dual_", today, ".pdf")))

#-------------------------------------------------------------------------


#dprimes for all task conditions (single and dual)
nback_cond <- c("1-back-dual", "2-back-dual", "0-back-dual", "1-back-single","2-back-single")
dual_plot_df <- df_all_data %>% 
  filter(cognitive_load %in% nback_cond)
dual_plot_df <- setNames(aggregate(dual_plot_df$dprime,
                              by = list(dual_plot_df$participant, dual_plot_df$condition, dual_plot_df$cognitive_load),
                              FUN = mean),
                    c("participant", "Task", "Condition", "Mean_dprime"))

# plot d-primes

plot_dprimes_all <- ggplot(dual_plot_df, aes(x=Condition,
                                    y = Mean_dprime, 
                               fill = Task,
                               color = Task), 
                            width = 4, height = 7) +
                      #geom_point(aes(color = Condition, fill = Condition), 
                      #       position = position_jitter(width = 0.04, height = 0),
                      #       alpha = 0.3,
                      #       shape = 19,
                      #       size = 1) +
                      #geom_violinhalf(flip = c(1,3)) +
                      geom_boxplot() +
                      scale_color_manual(values = palet_dprimes_lines) +
                      scale_fill_manual(values = palet_dprimes) +
                      theme_classic(14) +
                      theme(legend.position=("bottom"))+
                      coord_cartesian(ylim = c(0, 5))+
                      labs(y="Mean dprime", title="Mean dprime score per task per condition")
#this plot only has the dual task condition, but we want one that has both
plot(plot_dprimes_all)
cowplot::save_plot(plot_dprimes_all, file = here::here(paste0("Plots/dprimes_all_", today, ".pdf")))

#--------------------------------------------------------------------------------------

#question accuracy for dual and reading conditions
nback_cond <- c("1-back-dual", "2-back-dual", "0-back-dual", "Reading only")
dual_plot_df <- df_all_data %>% 
  filter(cognitive_load %in% nback_cond)

dual_plot_df <- setNames(aggregate(dual_plot_df$question_acc,
                              by = list(dual_plot_df$participant, dual_plot_df$condition, dual_plot_df$cognitive_load),
                              FUN = mean),
                    c("participant", "Task", "Condition", "Mean_percent_correct"))

## for PACED blocks:
# if it's the training block, we have three questions for accuracy
# if it'S another dual paced block, we have only one question per text
# Needs to be fixed later, first participants still had three questions per block


# calculate percentage
dual_plot_df$Mean_percent_correct <- dual_plot_df$Mean_percent_correct * 100

# plot % correct by condition & age
plot_comprehensionQs <- ggplot(dual_plot_df,
                               aes(x = Condition,
                                   y = Mean_percent_correct, 
                                   fill = Task,
                                   color = Task)) +
                         geom_violinhalf() +
                         geom_jitter2(mapping = aes(group = participant), width = 0.2) +
                         scale_color_manual(values = palet_task_condition_lines) +
                         scale_fill_manual(values = palet_task_condition) +
                         # scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
                         theme_classic(14) +
                         #coord_cartesian(ylim = c(0, 1),
                        #                xlim = c(18, 85)) +
                         theme(legend.position = "bottom")+
                         labs(y="Mean of correct answers in percent", title="Mean percentage of correct answers per condition per task")
plot(plot_comprehensionQs)            
ggsave(plot_comprehensionQs, 
       file = here::here(paste0("Plots/compr_Qs_", today, ".pdf")), 
       device = "pdf", width = 4, height = 4)

#---------------------------------------------------------------------------------------------
# question accuracy and age
nback_cond <- c("1-back-dual", "2-back-dual", "0-back-dual", "Reading only")
dual_plot_df <- df_all_data %>% 
  filter(cognitive_load %in% nback_cond)

dual_plot_df <- setNames(aggregate(dual_plot_df$question_acc,
                              by = list(dual_plot_df$participant, dual_plot_df$condition, dual_plot_df$cognitive_load, dual_plot_df$age),
                              FUN = mean),
                    c("participant", "Task", "Cognitive_Load", "age", "Mean_percent_correct"))


# calculate percentage
dual_plot_df$Mean_percent_correct <- dual_plot_df$Mean_percent_correct * 100

# plot % correct by condition & age
plot_comprehensionQs_age <- ggplot(dual_plot_df,
                               aes(x = age,
                                   y = Mean_percent_correct, 
                                   fill = Cognitive_Load,
                                   color = Cognitive_Load,
                                   group = Cognitive_Load))+
                         geom_smooth(method = lm)+
                         facet_wrap(~ Task)+
                         geom_jitter2(mapping = aes(group = Cognitive_Load), width = 0.2) +
                        #scale_color_manual(values = palet_task_condition_lines) +
                        #scale_fill_manual(values = palet_task_condition) +
                         # scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
                         theme_classic(14) +
                         #coord_cartesian(ylim = c(0, 1),
                        #                xlim = c(18, 85)) +
                         theme(legend.position = "bottom")+
                         labs(y="Mean of correct answers in percent", title="Mean percentage of correct answers per condition per task")
plot(plot_comprehensionQs_age)            
ggsave(plot_comprehensionQs_age, 
       file = here::here(paste0("Plots/compr_Qs_age", today, ".pdf")))
      # device = "pdf", width = 4, height = 4)
```

# plot duration by age per condition and task for all conditions
```{r}
df_all_data$age <- as.numeric(as.character(df_all_data$age))
df_all_data$condition <- factor(df_all_data$condition, levels = c("unpaced", "paced"))


plot_RT_age_cond_task <- ggplot(df_all_data, aes(x=age, y=duration, color=cognitive_load, fill=cognitive_load))+
  geom_smooth(method = lm) +
  facet_wrap(~ condition)+
  theme_classic(14)
plot_RT_age_cond_task

ggsave(plot_RT_age_cond_task, file = here::here(paste0("Plots/RTandAgeperConditionandTask_",today, ".pdf")))

```

# demographic plots
```{r}
#age distribution
plot_age_distribution <- ggplot(df_all_data, aes(x=age))+
  geom_density()+
  theme_classic()
plot_age_distribution

#gender distribution
plot_gender_distribution <- ggplot(df_all_data, aes(x=gender, fill=gender))+
  geom_bar()+
  theme_classic()
plot_gender_distribution

#gender distribution per age group
df_all_data_factor <- df_all_data
df_all_data$group <- ifelse(grepl("MA", df_all_data$participant), "middle-aged", 
                        ifelse(grepl("YA", df_all_data$participant), "young", "old"))
#df_all_data_factor <- as.factor(df_all_data$group)


plot_gender_age_distribution <- ggplot(df_all_data, aes(x=gender, fill=group, group = group))+
  geom_bar()+
  # facet_wrap(~ participant)+
  theme_classic()
plot_gender_age_distribution
```


## Plot RTs by Surprisal TS, Task & Condition (only dual-task blocks)
# again, needs to wait until surprisal scores are calculated
```{r plot RTs by Surprisal TS & Condition, message = FALSE, warning = FALSE}
plot_surprisal_df <- subset(df_clean, reaction == F) # exclude trials where you had a reaction



plot_surprisal_df <- pivot_longer(plot_surprisal_df, 
                                  cols = c("surprisal_1", "surprisal_4",
                                           "surprisal_12", "surprisal_60"),  
                                  names_to = "surprisal_ts", 
                                  values_to = "surprisal") %>% 
  select(c(surprisal_ts, participant, surprisal, cognitive_load, duration, condition)) 

plot_surprisal_df$surprisal <- round(plot_surprisal_df$surprisal, digits = 0)
# Now group by participant, cognitive_load & time scale
plot_surprisal_df <- plot_surprisal_df %>% 
                    #group_by(participant, cognitive_load, surprisal_ts, surprisal) %>% 
                    #summarise(mean_rt = mean(duration)) %>% 
                            rename(Surprisal_TS = surprisal_ts, 
                                   Subject = participant,
                                   Surprisal = surprisal,
                                   Cognitive_Load = cognitive_load,
                                   Reaction_time = duration,
                                   Condition = condition)

plot_surprisal_df$Surprisal_TS <- factor(plot_surprisal_df$Surprisal_TS, levels = c("surprisal_1", "surprisal_4", "surprisal_12", "surprisal_60"))

#plot_surprisal_df_summary <- plot_surprisal_df %>% 
#  group_by(Subject, Cognitive_Load) %>% 
#  summarise(Reaction_time = mean(Reaction_time))

#---- Plot RTs by Surprisal x Task ----
plot_RT_surprisal_task <- ggplot(plot_surprisal_df, aes(x = Surprisal, y = Reaction_time, fill = Condition, color = Condition)) +
                      geom_smooth(method = lm, aes(fill = Condition), na.rm = T) +
                      #geom_point2(plot_surprisal_df_summary, mapping = aes(x = Cognitive_Load, y = Reaction_time)) +
                      scale_color_manual(values = palet_task_condition) +
                      scale_fill_manual(values = palet_task_condition) +
                      scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +
                      facet_wrap(~ Surprisal_TS, ncol = 4) +
                      theme_classic(14) +
                      theme(
                            strip.background.x=element_rect(color = NA))

# save plot
cowplot::save_plot(plot_RT_surprisal_task, file = here::here(paste0("Plots/RT_surprisal_task_", today, ".pdf")))

#---- Plot RTs by Surprisal x Cognitive Load ----
plot_RT_surprisal_cond <- ggplot(plot_surprisal_df, aes(x = Surprisal, y = Reaction_time, fill = Cognitive_Load, color = Cognitive_Load)) +
                      geom_smooth(method = lm, aes(fill = Cognitive_Load), na.rm = T) +
                      #geom_point2(plot_surprisal_df_summary, mapping = aes(x = Cognitive_Load, y = Reaction_time)) +
                      scale_color_manual(values = palet_load) +
                      scale_fill_manual(values = palet_load) +
                      scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +
                      facet_wrap(~ Surprisal_TS, ncol = 4) +
                      theme_classic(14) +
                      theme(legend.position = "none",
                            strip.background.x=element_rect(color = NA))

# save plot
cowplot::save_plot(plot_RT_surprisal_cond, file = here::here(paste0("Plots/RT_surprisal_condition_", today, ".pdf")))

#---- Plot RTs by Surprisal x Cognitive Load x Condition ----
plot_RT_surprisal_task_cond <- ggplot(plot_surprisal_df, aes(x = Surprisal, y = Reaction_time, fill = Cognitive_Load, color = Cognitive_Load)) +
                      geom_smooth(method = lm, aes(fill = Cognitive_Load), na.rm = T) +
                      #geom_point2(plot_surprisal_df_summary, mapping = aes(x = Cognitive_Load, y = Reaction_time)) +
                      scale_color_manual(values = palet_load) +
                      scale_fill_manual(values = palet_load) +
                      scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +
                      facet_wrap(~ Condition + Surprisal_TS, ncol = 4) +
                      theme_classic(14) +
                      theme(legend.position = "none",
                            strip.background.x=element_rect(color = NA))

# save plot
cowplot::save_plot(plot_RT_surprisal_task_cond, file = here::here(paste0("Plots/RT_surprisal_task_condition_", today, ".pdf")))
```

#Plots for OA01
```{r}
plot_df <- subset(df_all_data, reaction == F)
OA01_df <- plot_df %>% filter(str_detect(participant, "OA01"))



#---- RTs by Task and Condition ----
plot_RT_task_cond_OA01 <- ggplot(df_all_data, aes(x = cognitive_load, y = duration, fill = condition, color = condition)) +
                      #geom_violinhalf(flip = c(1,3,5)) +
                      geom_boxplot() +
                      geom_boxplot(OA01_df, mapping = aes(x = cognitive_load, y = duration, fill = condition, color = condition), color = "red", fill = "red", size = 0.1, alpha = 0.4) +
                      #geom_point2(plot_surprisal_df_summary, mapping = aes(x = Cognitive_Load, y = Reaction_time)) +
                      scale_color_manual(values = palet_task_condition_lines) +
                      scale_fill_manual(values = palet_task_condition) +
                      #facet_wrap(~ Surprisal_TS, ncol = 4) +
                      theme_classic(14)+
                      #theme(legend.position = "none",
                      #      strip.background.x=element_rect(color = NA))
                      labs(x="Cognitive Load", y="Duration", title="Reading time per condition per task")
plot_RT_task_cond_OA01

# save plot
cowplot::save_plot(plot_RT_task_cond_OA01, file = here::here(paste0("Plots/RT_task_cond_OA01_", today, ".pdf")))

#-----------------------------------------------------------------------------

#dprimes for all task conditions (single and dual)
nback_cond <- c("1-back-dual", "2-back-dual", "0-back-dual", "1-back-single","2-back-single")
OA01_dual_df <- OA01_df %>% 
  filter(cognitive_load %in% nback_cond)
OA01_dual_df <- setNames(aggregate(OA01_dual_df$dprime,
                              by = list(OA01_dual_df$participant, OA01_dual_df$condition, OA01_dual_df$cognitive_load),
                              FUN = mean),
                    c("participant", "Task", "Condition", "Mean_dprime"))

# plot d-primes

plot_dprimes_OA01 <- ggplot(OA01_dual_df, aes(x=Condition,
                                    y = Mean_dprime, 
                               fill = Task,
                               color = Task), 
                            width = 4, height = 7) +
                      #geom_point(aes(color = Condition, fill = Condition), 
                      #       position = position_jitter(width = 0.04, height = 0),
                      #       alpha = 0.3,
                      #       shape = 19,
                      #       size = 1) +
                      #geom_violinhalf(flip = c(1,3)) +
                      geom_point2() +
                      # geom_boxplot() +
                      scale_color_manual(values = palet_dprimes_lines) +
                      scale_fill_manual(values = palet_dprimes) +
                      theme_classic(14) +
                      theme(legend.position=("bottom"))+
                      coord_cartesian(ylim = c(0, 5))+
                      labs(y="Mean dprime", title="Mean dprime score per task per condition")

plot(plot_dprimes_OA01)
cowplot::save_plot(plot_dprimes_all, file = here::here(paste0("Plots/dprimes_OA01_", today, ".pdf")))

#-------------------------------------------------------------------------------------------------------------------------

#question accuracy for dual and reading conditions
nback_cond <- c("1-back-dual", "2-back-dual", "0-back-dual", "Reading only")
OA01_dual_df <- OA01_df %>% 
  filter(cognitive_load %in% nback_cond)

OA01_dual_df <- setNames(aggregate(OA01_dual_df$question_acc,
                              by = list(OA01_dual_df$participant, OA01_dual_df$condition, OA01_dual_df$cognitive_load),
                              FUN = mean),
                    c("participant", "Task", "Condition", "Mean_percent_correct"))

## for PACED blocks:
# if it's the training block, we have three questions for accuracy
# if it'S another dual paced block, we have only one question per text
# Needs to be fixed later, first participants still had three questions per block


# calculate percentage
OA01_dual_df$Mean_percent_correct <- OA01_dual_df$Mean_percent_correct * 100

# plot % correct by condition & age
plot_comprehensionQs_OA01 <- ggplot(OA01_dual_df,
                               aes(x = Condition,
                                   y = Mean_percent_correct, 
                                   fill = Task,
                                   color = Task)) +
                         geom_point2(size = 12) +
                         # geom_violinhalf(trim = F) +
                         # geom_jitter2(mapping = aes(group = participant), width = 0.2) +
                         scale_color_manual(values = palet_task_condition_lines) +
                         scale_fill_manual(values = palet_task_condition) +
                         # scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
                         theme_classic(14) +
                         #coord_cartesian(ylim = c(0, 1),
                        #                xlim = c(18, 85)) +
                         theme(legend.position = "bottom")+
                         labs(y="Mean of correct answers in percent", title="Mean percentage of correct answers per condition per task")
plot(plot_comprehensionQs_OA01)            
ggsave(plot_comprehensionQs_OA01, 
       file = here::here(paste0("Plots/compr_Qs_OA01_", today, ".pdf")), 
       device = "pdf", width = 4, height = 4)
```


```{r}
#lmm_df <- subset(df_clean, !is.na(surprisal_60))
#m1 <- lmer(log(duration) ~ surprisal_1 * cognitive_load * condition + (cognitive_load|participant), data = lmm_df)

#plot(ggemmeans(m1, terms = c("surprisal_1", "cognitive_load", "condition")))
```



